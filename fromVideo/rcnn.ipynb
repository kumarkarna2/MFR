{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From m:\\.venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mm:\\fromVideo\\rcnn.ipynb Cell 1\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(X), np\u001b[39m.\u001b[39masarray(y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m# Load train dataset\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m X_train, y_train \u001b[39m=\u001b[39m load_dataset(\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m     \u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mM:/14-celebrity-faces-dataset/data/train\u001b[39;49m\u001b[39m\"\u001b[39;49m, use_haarcascades\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain Dataset Shape: \u001b[39m\u001b[39m{\u001b[39;00mX_train\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, Labels Shape: \u001b[39m\u001b[39m{\u001b[39;00my_train\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# Load validation dataset\u001b[39;00m\n",
      "\u001b[1;32mm:\\fromVideo\\rcnn.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(path):\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m faces, labels \u001b[39m=\u001b[39m load_faces(path, use_haarcascades)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoaded \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(faces)\u001b[39m}\u001b[39;00m\u001b[39m examples for class: \u001b[39m\u001b[39m{\u001b[39;00msubdir\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m X\u001b[39m.\u001b[39mextend(faces)\n",
      "\u001b[1;32mm:\\fromVideo\\rcnn.ipynb Cell 1\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(directory):\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m     path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, filename)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     face, _ \u001b[39m=\u001b[39m extract_face(filename\u001b[39m=\u001b[39;49mpath, use_haarcascades\u001b[39m=\u001b[39;49muse_haarcascades)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mif\u001b[39;00m face \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         faces\u001b[39m.\u001b[39mappend(face)\n",
      "\u001b[1;32mm:\\fromVideo\\rcnn.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(pixels, cv2\u001b[39m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m face_cascade \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mCascadeClassifier(\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     cv2\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mhaarcascades \u001b[39m+\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK:/FaceRecognization/haarcascade_frontalface_default.xml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m faces \u001b[39m=\u001b[39m face_cascade\u001b[39m.\u001b[39;49mdetectMultiScale(gray, scaleFactor\u001b[39m=\u001b[39;49m\u001b[39m1.3\u001b[39;49m, minNeighbors\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(faces) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/m%3A/fromVideo/rcnn.ipynb#W0sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\objdetect\\src\\cascadedetect.cpp:1689: error: (-215:Assertion failed) !empty() in function 'cv::CascadeClassifier::detectMultiScale'\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "from cv2 import imread\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from keras_facenet import FaceNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def extract_face(\n",
    "    filename=None, image_pixels=None, required_size=(160, 160), use_haarcascades=False\n",
    "):\n",
    "    if filename is not None:\n",
    "        image = imread(filename)\n",
    "        image = Image.fromarray(image)\n",
    "        pixels = np.asarray(image)\n",
    "    elif image_pixels is not None:\n",
    "        pixels = image_pixels\n",
    "\n",
    "    if use_haarcascades:\n",
    "        gray = cv2.cvtColor(pixels, cv2.COLOR_RGB2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(\n",
    "            cv2.data.haarcascades + r\"K:/FaceRecognization/haarcascade_frontalface_default.xml\"\n",
    "        )\n",
    "        faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            return None, None\n",
    "\n",
    "        x, y, w, h = faces[0]\n",
    "        face = pixels[y : y + h, x : x + w]\n",
    "        box_dimensions = (x, y, w, h)\n",
    "\n",
    "    else:\n",
    "        detector = MTCNN()\n",
    "        results = detector.detect_faces(pixels)\n",
    "        if not results:\n",
    "            return None, None\n",
    "\n",
    "        x1, y1, width, height = results[0][\"box\"]\n",
    "        x1, y1 = abs(x1), abs(y1)\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        face = pixels[y1:y2, x1:x2]\n",
    "        box_dimensions = (x1, y1, width, height)\n",
    "\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array, box_dimensions\n",
    "\n",
    "\n",
    "def load_faces(directory, use_haarcascades=False):\n",
    "    faces = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        path = os.path.join(directory, filename)\n",
    "        face, _ = extract_face(filename=path, use_haarcascades=use_haarcascades)\n",
    "        if face is not None:\n",
    "            faces.append(face)\n",
    "            labels.append(\n",
    "                directory.split(\"/\")[-1]\n",
    "            )  # Assuming directory structure is like '.../data/class_name/'\n",
    "    return faces, labels\n",
    "\n",
    "\n",
    "def load_dataset(directory, use_haarcascades=False):\n",
    "    X, y = [], []\n",
    "    for subdir in os.listdir(directory):\n",
    "        path = os.path.join(directory, subdir)\n",
    "        if not os.path.isdir(path):\n",
    "            continue\n",
    "        faces, labels = load_faces(path, use_haarcascades)\n",
    "        print(f\"Loaded {len(faces)} examples for class: {subdir}\")\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "\n",
    "# Load train dataset\n",
    "X_train, y_train = load_dataset(\n",
    "    r\"M:/14-celebrity-faces-dataset/data/train\", use_haarcascades=True\n",
    ")\n",
    "print(f\"Train Dataset Shape: {X_train.shape}, Labels Shape: {y_train.shape}\")\n",
    "\n",
    "# Load validation dataset\n",
    "X_val, y_val = load_dataset(\n",
    "    r\"M:/14-celebrity-faces-dataset/data/val\", use_haarcascades=True\n",
    ")\n",
    "print(f\"Validation Dataset Shape: {X_val.shape}, Labels Shape: {y_val.shape}\")\n",
    "\n",
    "# Load the FaceNet model with pre-trained weights\n",
    "model = FaceNet()\n",
    "\n",
    "# Convert each face in the training set to an embedding\n",
    "train_embeddings = []\n",
    "for face_pixels in X_train:\n",
    "    embedding = model.model.predict(np.expand_dims(face_pixels / 255.0, axis=0))[0]\n",
    "    train_embeddings.append(embedding)\n",
    "train_embeddings = np.asarray(train_embeddings)\n",
    "print(f\"Train Embeddings Shape: {train_embeddings.shape}\")\n",
    "\n",
    "# Convert each face in the validation set to an embedding\n",
    "val_embeddings = []\n",
    "for face_pixels in X_val:\n",
    "    embedding = model.model.predict(np.expand_dims(face_pixels / 255.0, axis=0))[0]\n",
    "    val_embeddings.append(embedding)\n",
    "val_embeddings = np.asarray(val_embeddings)\n",
    "print(f\"Validation Embeddings Shape: {val_embeddings.shape}\")\n",
    "\n",
    "# Label encoding for SVM\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_classifier = SVC(kernel=\"linear\", probability=True)\n",
    "svm_classifier.fit(train_embeddings, y_train_encoded)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = svm_classifier.predict(val_embeddings)\n",
    "accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96164, Maple Place, 10nd Cross\n",
      "31327, Main Place\n",
      "57615, Park Avenue\n",
      "78616, Hill Way\n",
      "45896, 4th Drive\n",
      "8263, 7th Place\n",
      "43067, Oak Road\n",
      "15003, Oak Way\n",
      "32567, River Avenue\n",
      "23825, 4th Way\n",
      "5381, Oak Avenue, 14nd Cross\n",
      "6522, 9th Place\n",
      "64614, Elm Road\n",
      "26575, 3rd Street\n",
      "35433, 1st Avenue\n",
      "3815, 7th Lane, 7rd Cross\n",
      "28877, 7th Drive\n",
      "97104, 2nd Place\n",
      "49315, Elm Place, 11st Cross\n",
      "94309, 7th Lane\n",
      "58064, 6th Drive\n",
      "42141, Elm Drive\n",
      "86802, 9th Way\n",
      "86321, 6th Avenue\n",
      "83946, Maple Court\n",
      "93713, Lake Road\n",
      "90575, 9th Street\n",
      "87781, Main Drive\n",
      "4877, Hill Road\n",
      "30295, 8th Way, 13st Cross\n",
      "16489, Main Place, 8rd Cross\n",
      "112, 10th Avenue\n",
      "28607, Lake Court\n",
      "23575, Maple Way, 15rd Cross\n",
      "86397, Maple Road\n",
      "56683, 1st Lane\n",
      "56323, 4th Street, 2rd Cross\n",
      "15986, 7th Road, 1rd Cross\n",
      "69558, Lake Drive\n",
      "76142, 4th Place, 1nd Cross\n",
      "93629, Maple Road\n",
      "36298, 6th Avenue, 1st Cross\n",
      "57968, 6th Court, 3th Cross\n",
      "89155, 4th Street\n",
      "14361, Park Place, 2nd Cross\n",
      "19064, River Road, 20nd Cross\n",
      "99533, River Street\n",
      "66792, Lake Way, 5nd Cross\n",
      "21712, Maple Drive, 1th Cross\n",
      "70352, Oak Court\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "street_prefixes = [\n",
    "    \"1st\",\n",
    "    \"2nd\",\n",
    "    \"3rd\",\n",
    "    \"4th\",\n",
    "    \"5th\",\n",
    "    \"6th\",\n",
    "    \"7th\",\n",
    "    \"8th\",\n",
    "    \"9th\",\n",
    "    \"10th\",\n",
    "    \"Main\",\n",
    "    \"Elm\",\n",
    "    \"Oak\",\n",
    "    \"Pine\",\n",
    "    \"Maple\",\n",
    "    \"Hill\",\n",
    "    \"Lake\",\n",
    "    \"River\",\n",
    "    \"Park\",\n",
    "]\n",
    "street_suffixes = [\"Street\", \"Avenue\", \"Road\", \"Lane\", \"Drive\", \"Place\", \"Court\", \"Way\"]\n",
    "\n",
    "\n",
    "def generate_address():\n",
    "    house_number = str(random.randint(100, 99999))\n",
    "    street_prefix = random.choice(street_prefixes)\n",
    "    street_suffix = random.choice(street_suffixes)\n",
    "    cross_street = (\n",
    "        str(random.randint(1, 20)) + random.choice([\"st\", \"nd\", \"rd\", \"th\"]) + \" Cross\"\n",
    "    )\n",
    "\n",
    "    # Determine if there's a comma and cross street\n",
    "    if random.random() > 0.3:  # 70% chance of having no comma/cross street\n",
    "        return f\"{house_number}, {street_prefix} {street_suffix}\"\n",
    "    else:\n",
    "        return f\"{house_number}, {street_prefix} {street_suffix}, {cross_street}\"\n",
    "\n",
    "\n",
    "for _ in range(50):  # Generate 5 addresses\n",
    "    print(generate_address())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
